{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12f3ddcc",
   "metadata": {},
   "source": [
    "### Preparing the data for the DeepSignalingFlow model\n",
    "\n",
    "Code copied from the authors of \"Using DeepSignalingFlow to mine signaling ows interpreting mechanism of synergy of cocktails\".\n",
    "\n",
    "You can find the original code [here](https://github.com/FuhaiLiAiLab/DeepSignalingFlow/blob/main/load_data.py).\n",
    "\n",
    "All changes are marked with the comment `# Change in original code` with the following explanation of the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9592fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import inf\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970b44d7",
   "metadata": {},
   "source": [
    "The following cell contains the class for preprocessing the given data. There is a lot of everything, so will explain the functions and overall process briefly.\n",
    "\n",
    "The load_batch method:\n",
    "- loads a split of the input data containing drug/cell line combinations;\n",
    "- loads gene annotation data to get the list of genes;\n",
    "- loads gene expression (RNA) and copy number variation (CNV) data for all genes and cell lines;\n",
    "- loads drug-target interaction data from DrugBank;\n",
    "- loads a mapping from drug names to numeric IDs.\n",
    "\n",
    "The load_all_split method:\n",
    "- iterates over all data folds and loads the relevant data (gene annotations and drug dictionary);\n",
    "- for each batch, uses the previous method to get the features, labels and IDs;\n",
    "- saves the features, labels and IDs for splits.\n",
    "\n",
    "The load_train_test method:\n",
    "- loads gene and drug information to determine the feature dimensions;\n",
    "- for each split, either loads it as test data, or as train data.\n",
    "\n",
    "The combine_whole_dataset method:\n",
    "- combines all folds into one dataset.\n",
    "\n",
    "The load_adj_edgeindex method:\n",
    "- creates the adjacency matrix and edge index for gene-drug interaction graph;\n",
    "- adjacency matrix: represents all gene-gene and drug-gene (target) relationships;\n",
    "- edge index array: lists all edges as pairs of node indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55c4f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadData():\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        pass\n",
    "\n",
    "    def load_batch(self, index, upper_index, place_num, drug_feature=False):\n",
    "        # PRELOAD EACH SPLIT DATASET\n",
    "        split_input_df = pd.read_csv('./' + self.dataset+ '/filtered_data/split_input_' + str(place_num + 1) + '.csv')\n",
    "        num_feature = 4\n",
    "        final_annotation_gene_df = pd.read_csv('./' + self.dataset+ '/filtered_data/kegg_gene_annotation.csv')\n",
    "        gene_name_list = list(final_annotation_gene_df['kegg_gene'])\n",
    "        print('READING GENE FEATURES FILES ...')\n",
    "        final_gdsc_rna_df = pd.read_csv('./' + self.dataset+ '/filtered_data/final_rna.csv')\n",
    "        final_gdsc_cnv_df = pd.read_csv('./' + self.dataset+ '/filtered_data/final_cnv.csv')\n",
    "        num_gene, num_cellline = final_gdsc_rna_df.shape\n",
    "        # CONVERT [drugbank.csv] TO A LIST\n",
    "        print('READING DRUGBANK ...')\n",
    "        final_drugbank_df = pd.read_csv('./' + self.dataset+ '/filtered_data/final_drugbank.csv')\n",
    "        final_drugbank_comlist = final_drugbank_df.values.tolist()\n",
    "        print('READING DRUGDICT ...')\n",
    "        drug_num_dict_df = pd.read_csv('./' + self.dataset+ '/filtered_data/drug_num_dict.csv')\n",
    "        drug_dict = dict(zip(drug_num_dict_df.Drug, drug_num_dict_df.drug_num))\n",
    "        num_drug = len(drug_dict)\n",
    "        print('READING FINISHED ...')\n",
    "        # COMBINE A BATCH SIZE AS [x_batch, y_batch, drug_batch]\n",
    "        print('-----' + str(index) + ' to ' + str(upper_index) + '-----')\n",
    "        tmp_batch_size = 0\n",
    "        y_input_list = []\n",
    "        drug_input_list = []\n",
    "        x_batch = np.zeros((1, (num_feature * (num_gene + num_drug))))\n",
    "        for row in split_input_df.iloc[index : upper_index].itertuples():\n",
    "            tmp_batch_size += 1\n",
    "            drug_a = row[1]\n",
    "            drug_b = row[2]\n",
    "            cellline_name = row[3]\n",
    "            if self.dataset == 'data-drugcomb-fi':\n",
    "                y = row[5]\n",
    "            else:\n",
    "                y = row[4]\n",
    "            # DRUG_A AND [4853] TARGET GENES\n",
    "            one_drug_target_list = []\n",
    "            duo_drug_target_list = []\n",
    "            for gene in gene_name_list:\n",
    "                drugA_target = [drug_a, gene] in final_drugbank_comlist\n",
    "                drugB_target = [drug_b, gene] in final_drugbank_comlist\n",
    "                if drugA_target and drugB_target:\n",
    "                    one_drug_target_list.append(0.0)\n",
    "                    duo_drug_target_list.append(1.0)\n",
    "                elif drugA_target or drugB_target:\n",
    "                    one_drug_target_list.append(1.0)\n",
    "                    duo_drug_target_list.append(0.0)\n",
    "                else:\n",
    "                    one_drug_target_list.append(0.0)\n",
    "                    duo_drug_target_list.append(0.0)\n",
    "            # GENE FEATURES SEQUENCE\n",
    "            gene_rna_list = [float(x) for x in list(final_gdsc_rna_df[cellline_name])]\n",
    "            gene_cnv_list = [float(x) for x in list(final_gdsc_cnv_df[cellline_name])]\n",
    "            # COMBINE [drugA, drugB, rna, cmeth] \n",
    "            x_input_list = []\n",
    "            for i in range(num_gene):\n",
    "                # APPEND DRUG INFORMATION\n",
    "                x_input_list.append(one_drug_target_list[i])\n",
    "                x_input_list.append(duo_drug_target_list[i])\n",
    "                # APPEND GENE FEATURES\n",
    "                x_input_list.append(gene_rna_list[i])\n",
    "                x_input_list.append(gene_cnv_list[i])\n",
    "            if drug_feature == False:\n",
    "                fillin_list = [0.0] * num_feature\n",
    "                for i in range(num_drug):\n",
    "                    x_input_list += fillin_list\n",
    "            x_input = np.array(x_input_list)\n",
    "            x_batch = np.vstack((x_batch, x_input))\n",
    "            # COMBINE DRUG[A/B] LIST\n",
    "            drug_input_list.append(drug_dict[drug_a])\n",
    "            drug_input_list.append(drug_dict[drug_b])\n",
    "            # COMBINE SCORE LIST\n",
    "            y_input_list.append(y)\n",
    "        # import pdb; pdb.set_trace()\n",
    "        x_batch = np.delete(x_batch, 0, axis = 0)\n",
    "        y_batch = np.array(y_input_list).reshape(tmp_batch_size, 1)\n",
    "        drug_batch = np.array(drug_input_list).reshape(tmp_batch_size, 2)\n",
    "        print(x_batch.shape)\n",
    "        print(y_batch.shape)\n",
    "        print(drug_batch.shape)\n",
    "        return x_batch, y_batch, drug_batch\n",
    "\n",
    "\n",
    "    def load_all_split(self, batch_size, k):\n",
    "        form_data_path = './' + self.dataset+ '/form_data'\n",
    "        # LOAD 100 PERCENT DATA\n",
    "        print('LOADING ALL SPLIT DATA...')\n",
    "        # FIRST LOAD EACH SPLIT DATA\n",
    "        for place_num in range(k):\n",
    "            split_input_df = pd.read_csv('./' + self.dataset+ '/filtered_data/split_input_' + str(place_num + 1) + '.csv')\n",
    "            input_num, input_dim = split_input_df.shape\n",
    "            num_feature = 4\n",
    "            final_annotation_gene_df = pd.read_csv('./' + self.dataset+ '/filtered_data/kegg_gene_annotation.csv')\n",
    "            gene_name_list = list(final_annotation_gene_df['kegg_gene'])\n",
    "            num_gene = len(gene_name_list)\n",
    "            drug_num_dict_df = pd.read_csv('./' + self.dataset+ '/filtered_data/drug_num_dict.csv')\n",
    "            drug_dict = dict(zip(drug_num_dict_df.Drug, drug_num_dict_df.drug_num))\n",
    "            num_drug = len(drug_dict)\n",
    "            x_split = np.zeros((1, num_feature * (num_gene + num_drug)))\n",
    "            y_split = np.zeros((1, 1))\n",
    "            drug_split = np.zeros((1, 2))\n",
    "            for index in range(0, input_num, batch_size):\n",
    "                if (index + batch_size) < input_num:\n",
    "                    upper_index = index + batch_size\n",
    "                else:\n",
    "                    upper_index = input_num\n",
    "                x_batch, y_batch, drug_batch = LoadData(self.dataset).load_batch(index, upper_index, place_num)\n",
    "                x_split = np.vstack((x_split, x_batch))\n",
    "                y_split = np.vstack((y_split, y_batch))\n",
    "                drug_split = np.vstack((drug_split, drug_batch))\n",
    "            x_split = np.delete(x_split, 0, axis = 0)\n",
    "            y_split = np.delete(y_split, 0, axis = 0)\n",
    "            drug_split = np.delete(drug_split, 0, axis = 0)\n",
    "            print('-------SPLIT DATA SHAPE-------')\n",
    "            print(x_split.shape)\n",
    "            print(y_split.shape)\n",
    "            print(drug_split.shape)\n",
    "            np.save(form_data_path + '/x_split' + str(place_num + 1) + '.npy', x_split)\n",
    "            np.save(form_data_path + '/y_split' + str(place_num + 1) + '.npy', y_split)\n",
    "            np.save(form_data_path + '/drug_split' + str(place_num + 1) + '.npy', drug_split)\n",
    "            \n",
    "\n",
    "    def load_train_test(self, k, n_fold):\n",
    "        form_data_path = './' + self.dataset+ '/form_data'\n",
    "        num_feature = 4\n",
    "        final_annotation_gene_df = pd.read_csv('./' + self.dataset+ '/filtered_data/kegg_gene_annotation.csv')\n",
    "        gene_name_list = list(final_annotation_gene_df['kegg_gene'])\n",
    "        num_gene = len(gene_name_list)\n",
    "        drug_num_dict_df = pd.read_csv('./' + self.dataset+ '/filtered_data/drug_num_dict.csv')\n",
    "        drug_dict = dict(zip(drug_num_dict_df.Drug, drug_num_dict_df.drug_num))\n",
    "        num_drug = len(drug_dict)\n",
    "        xTr = np.zeros((1, num_feature * (num_gene + num_drug)))\n",
    "        yTr = np.zeros((1, 1))\n",
    "        drugTr = np.zeros((1, 2))\n",
    "        for i in range(1, k + 1):\n",
    "            if i == n_fold:\n",
    "                print('--- LOADING ' + str(i) + '-TH SPLIT TEST DATA ---')\n",
    "                xTe = np.load(form_data_path + '/x_split' + str(i) + '.npy')\n",
    "                yTe = np.load(form_data_path + '/y_split' + str(i) + '.npy')\n",
    "                drugTe = np.load(form_data_path + '/drug_split' + str(i) + '.npy')\n",
    "            else:\n",
    "                print('--- LOADING ' + str(i) + '-TH SPLIT TRAINING DATA ---')\n",
    "                x_split = np.load(form_data_path + '/x_split' + str(i) + '.npy')\n",
    "                y_split = np.load(form_data_path + '/y_split' + str(i) + '.npy')\n",
    "                drug_split = np.load(form_data_path + '/drug_split' + str(i) + '.npy')\n",
    "                print('--- COMBINING DATA ... ---')\n",
    "                xTr = np.vstack((xTr, x_split))\n",
    "                yTr = np.vstack((yTr, y_split))\n",
    "                drugTr = np.vstack((drugTr, drug_split))\n",
    "        print('--- TRAINING INPUT SHAPE ---')\n",
    "        xTr = np.delete(xTr, 0, axis = 0)\n",
    "        yTr = np.delete(yTr, 0, axis = 0)\n",
    "        drugTr = np.delete(drugTr, 0, axis = 0)\n",
    "        print(xTr.shape)\n",
    "        print(yTr.shape)\n",
    "        print(drugTr.shape)\n",
    "        np.save(form_data_path + '/xTr' + str(n_fold) + '.npy', xTr)\n",
    "        np.save(form_data_path + '/yTr' + str(n_fold) + '.npy', yTr)\n",
    "        np.save(form_data_path + '/drugTr' + str(n_fold) + '.npy', drugTr)\n",
    "        print('--- TEST INPUT SHAPE ---')\n",
    "        print(xTe.shape)\n",
    "        print(yTe.shape)\n",
    "        print(drugTe.shape)\n",
    "        np.save(form_data_path + '/xTe' + str(n_fold) + '.npy', xTe)\n",
    "        np.save(form_data_path + '/yTe' + str(n_fold) + '.npy', yTe)\n",
    "        np.save(form_data_path + '/drugTe' + str(n_fold) + '.npy', drugTe)\n",
    "\n",
    "    def combine_whole_dataset(self, k):\n",
    "        form_data_path = './' + self.dataset+ '/form_data'\n",
    "        num_feature = 4\n",
    "        final_annotation_gene_df = pd.read_csv('./' + self.dataset+ '/filtered_data/kegg_gene_annotation.csv')\n",
    "        gene_name_list = list(final_annotation_gene_df['kegg_gene'])\n",
    "        num_gene = len(gene_name_list)\n",
    "        drug_num_dict_df = pd.read_csv('./' + self.dataset+ '/filtered_data/drug_num_dict.csv')\n",
    "        drug_dict = dict(zip(drug_num_dict_df.Drug, drug_num_dict_df.drug_num))\n",
    "        num_drug = len(drug_dict)\n",
    "        xAll = np.zeros((1, num_feature * (num_gene + num_drug)))\n",
    "        yAll = np.zeros((1, 1))\n",
    "        drugAll = np.zeros((1, 2))\n",
    "        for i in range(1, k + 1):\n",
    "            print('--- LOADING ' + str(i) + '-TH SPLIT TRAINING DATA ---')\n",
    "            x_split = np.load(form_data_path + '/x_split' + str(i) + '.npy')\n",
    "            y_split = np.load(form_data_path + '/y_split' + str(i) + '.npy')\n",
    "            drug_split = np.load(form_data_path + '/drug_split' + str(i) + '.npy')\n",
    "            print('--- COMBINING DATA ... ---')\n",
    "            xAll = np.vstack((xAll, x_split))\n",
    "            yAll = np.vstack((yAll, y_split))\n",
    "            drugAll = np.vstack((drugAll, drug_split))\n",
    "        print('--- ALL DATASET INPUT SHAPE ---')\n",
    "        xAll = np.delete(xAll, 0, axis = 0)\n",
    "        yAll = np.delete(yAll, 0, axis = 0)\n",
    "        drugAll = np.delete(drugAll, 0, axis = 0)\n",
    "        print(xAll.shape)\n",
    "        print(yAll.shape)\n",
    "        print(drugAll.shape)\n",
    "        np.save(form_data_path + '/xAll.npy', xAll)\n",
    "        np.save(form_data_path + '/yAll.npy', yAll)\n",
    "        np.save(form_data_path + '/drugAll.npy', drugAll)\n",
    "    \n",
    "    def load_adj_edgeindex(self):\n",
    "        form_data_path = './' + self.dataset+ '/form_data'\n",
    "        # FORM A WHOLE ADJACENT MATRIX\n",
    "        gene_num_df = pd.read_csv('./' + self.dataset+ '/filtered_data/kegg_gene_num_interaction.csv')\n",
    "        src_gene_list = list(gene_num_df['src'])\n",
    "        dest_gene_list = list(gene_num_df['dest'])\n",
    "        final_annotation_gene_df = pd.read_csv('./' + self.dataset+ '/filtered_data/kegg_gene_annotation.csv')\n",
    "        gene_name_list = list(final_annotation_gene_df['kegg_gene'])\n",
    "        num_gene = len(gene_name_list)\n",
    "        dict_drug_num = pd.read_csv('./' + self.dataset+ '/filtered_data/drug_num_dict.csv')\n",
    "        num_drug = dict_drug_num.shape[0]\n",
    "        num_node = num_gene + num_drug\n",
    "        adj = np.zeros((num_node, num_node))\n",
    "        # GENE-GENE ADJACENT MATRIX\n",
    "        for i in range(len(src_gene_list)):\n",
    "            row_idx = src_gene_list[i] - 1\n",
    "            col_idx = dest_gene_list[i] - 1\n",
    "            adj[row_idx, col_idx] = 1\n",
    "            adj[col_idx, row_idx] = 1 # WHETHER WE WANT ['sym']\n",
    "        # import pdb; pdb.set_trace()\n",
    "        # DRUG_TARGET ADJACENT MATRIX\n",
    "        drugbank_num_df = pd.read_csv('./' + self.dataset+ '/filtered_data/final_drugbank_num.csv')\n",
    "        drugbank_drug_list = list(drugbank_num_df['Drug'])\n",
    "        drugbank_target_list = list(drugbank_num_df['Target'])\n",
    "        for row in drugbank_num_df.itertuples():\n",
    "            row_idx = row[1] - 1\n",
    "            col_idx = row[2] - 1\n",
    "            adj[row_idx, col_idx] = 1\n",
    "            adj[col_idx, row_idx] = 1\n",
    "        # import pdb; pdb.set_trace()\n",
    "        # np.save(form_data_path + '/adj.npy', adj)\n",
    "        adj_sparse = sparse.csr_matrix(adj)\n",
    "        sparse.save_npz(form_data_path + '/adj_sparse.npz', adj_sparse)\n",
    "        # [edge_index]\n",
    "        genedrug_src_list = src_gene_list + drugbank_drug_list + drugbank_target_list\n",
    "        genedrug_dest_list = dest_gene_list + drugbank_target_list + drugbank_drug_list\n",
    "        genedrug_src_indexlist = []\n",
    "        genedrug_dest_indexlist = []\n",
    "        for i in range(len(genedrug_src_list)):\n",
    "            genedrug_src_index = genedrug_src_list[i] - 1\n",
    "            genedrug_src_indexlist.append(genedrug_src_index)\n",
    "            genedrug_dest_index = genedrug_dest_list[i] - 1\n",
    "            genedrug_dest_indexlist.append(genedrug_dest_index)\n",
    "        edge_index = np.column_stack((genedrug_src_indexlist, genedrug_dest_indexlist)).T\n",
    "        np.save(form_data_path + '/edge_index.npy', edge_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1293cc4c",
   "metadata": {},
   "source": [
    "This next function is just for random shuffle of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e390b472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOMIZE THE [final_NCI60_DeepLearningInput]\n",
    "def input_random(dataset):\n",
    "    final_input_df = pd.read_csv('./' + dataset + '/filtered_data/final_dl_input.csv')\n",
    "    random_final_input_df = final_input_df.sample(frac = 1)\n",
    "    random_final_input_df.to_csv('./' + dataset + '/filtered_data/random_final_dl_input.csv', index = False, header = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6469b5b0",
   "metadata": {},
   "source": [
    "The next cell calculates how many samples should go into each of the k folds, and splits the data into these defined folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95596104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT DEEP LEARNING INPUT INTO TRAINING AND TEST\n",
    "def split_k_fold(k, dataset):\n",
    "    random_final_dl_input_df = pd.read_csv('./' + dataset + '/filtered_data/random_final_dl_input.csv')\n",
    "    num_points = random_final_dl_input_df.shape[0]\n",
    "    num_div = int(num_points / k)\n",
    "    num_div_list = [i * num_div for i in range(0, k)]\n",
    "    num_div_list.append(num_points)\n",
    "    # SPLIT [RandomFinal_NCI60_DeepLearningInput] INTO [k] FOLDS\n",
    "    for place_num in range(k):\n",
    "        low_idx = num_div_list[place_num]\n",
    "        high_idx = num_div_list[place_num + 1]\n",
    "        print('\\n--------TRAIN-TEST SPLIT WITH TEST FROM ' + str(low_idx) + ' TO ' + str(high_idx) + '--------')\n",
    "        split_input_df = random_final_dl_input_df[low_idx : high_idx]\n",
    "        split_input_df.to_csv('./' + dataset + '/filtered_data/split_input_' + str(place_num + 1) + '.csv', index = False, header = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f902fc41",
   "metadata": {},
   "source": [
    "Main loop for data preprocessing. Just choose the raw data you want and run the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459c902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ############## MOUDLE 1 ################\n",
    "k = 5\n",
    "# DATASET SELECTION\n",
    "dataset = 'data-drugcomb-fi'\n",
    "# dataset = 'data-DrugCombDB'\n",
    "# dataset = 'data-nci'\n",
    "# dataset = 'data-oneil'\n",
    "\n",
    "input_random(dataset)\n",
    "split_k_fold(k, dataset)\n",
    "\n",
    "if os.path.exists('./' + dataset + '/form_data') == False:\n",
    "    os.mkdir('./' + dataset + '/form_data')\n",
    "batch_size = 64\n",
    "LoadData(dataset).load_all_split(batch_size, k)\n",
    "\n",
    "n_fold = 1\n",
    "# ############## MOUDLE 2 ################\n",
    "print('split_input_' + str(n_fold) + '.csv')\n",
    "LoadData(dataset).load_adj_edgeindex()\n",
    "\n",
    "################ MOUDLE 3 ################\n",
    "# FORM N-TH FOLD TRAINING DATASET\n",
    "LoadData(dataset).load_train_test(k, n_fold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
