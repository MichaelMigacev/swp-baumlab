{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12f3ddcc",
   "metadata": {},
   "source": [
    "### Preparing the data for the DeepSignalingFlow model\n",
    "\n",
    "Code copied from the authors of \"Using DeepSignalingFlow to mine signaling ows interpreting mechanism of synergy of cocktails\".\n",
    "\n",
    "You can find the original code [here](https://github.com/FuhaiLiAiLab/DeepSignalingFlow/blob/main/load_data.py).\n",
    "\n",
    "All changes are marked with the comment `# Change in original code` with the following explanation of the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9592fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import inf\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55c4f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadData():\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        pass\n",
    "\n",
    "    def load_batch(self, index, upper_index, place_num, drug_feature=False):\n",
    "        # PRELOAD EACH SPLIT DATASET\n",
    "        split_input_df = pd.read_csv('./' + self.dataset+ '/filtered_data/split_input_' + str(place_num + 1) + '.csv')\n",
    "        num_feature = 4\n",
    "        final_annotation_gene_df = pd.read_csv('./' + self.dataset+ '/filtered_data/kegg_gene_annotation.csv')\n",
    "        gene_name_list = list(final_annotation_gene_df['kegg_gene'])\n",
    "        print('READING GENE FEATURES FILES ...')\n",
    "        final_gdsc_rna_df = pd.read_csv('./' + self.dataset+ '/filtered_data/final_rna.csv')\n",
    "        final_gdsc_cnv_df = pd.read_csv('./' + self.dataset+ '/filtered_data/final_cnv.csv')\n",
    "        num_gene, num_cellline = final_gdsc_rna_df.shape\n",
    "        # CONVERT [drugbank.csv] TO A LIST\n",
    "        print('READING DRUGBANK ...')\n",
    "        final_drugbank_df = pd.read_csv('./' + self.dataset+ '/filtered_data/final_drugbank.csv')\n",
    "        final_drugbank_comlist = final_drugbank_df.values.tolist()\n",
    "        print('READING DRUGDICT ...')\n",
    "        drug_num_dict_df = pd.read_csv('./' + self.dataset+ '/filtered_data/drug_num_dict.csv')\n",
    "        drug_dict = dict(zip(drug_num_dict_df.Drug, drug_num_dict_df.drug_num))\n",
    "        num_drug = len(drug_dict)\n",
    "        print('READING FINISHED ...')\n",
    "        # COMBINE A BATCH SIZE AS [x_batch, y_batch, drug_batch]\n",
    "        print('-----' + str(index) + ' to ' + str(upper_index) + '-----')\n",
    "        tmp_batch_size = 0\n",
    "        y_input_list = []\n",
    "        drug_input_list = []\n",
    "        x_batch = np.zeros((1, (num_feature * (num_gene + num_drug))))\n",
    "        for row in split_input_df.iloc[index : upper_index].itertuples():\n",
    "            tmp_batch_size += 1\n",
    "            drug_a = row[1]\n",
    "            drug_b = row[2]\n",
    "            cellline_name = row[3]\n",
    "            if dataset == 'data-drugcomb-fi':\n",
    "                y = row[5]\n",
    "            else:\n",
    "                y = row[4]\n",
    "            # DRUG_A AND [4853] TARGET GENES\n",
    "            one_drug_target_list = []\n",
    "            duo_drug_target_list = []\n",
    "            for gene in gene_name_list:\n",
    "                drugA_target = [drug_a, gene] in final_drugbank_comlist\n",
    "                drugB_target = [drug_b, gene] in final_drugbank_comlist\n",
    "                if drugA_target and drugB_target:\n",
    "                    one_drug_target_list.append(0.0)\n",
    "                    duo_drug_target_list.append(1.0)\n",
    "                elif drugA_target or drugB_target:\n",
    "                    one_drug_target_list.append(1.0)\n",
    "                    duo_drug_target_list.append(0.0)\n",
    "                else:\n",
    "                    one_drug_target_list.append(0.0)\n",
    "                    duo_drug_target_list.append(0.0)\n",
    "            # GENE FEATURES SEQUENCE\n",
    "            gene_rna_list = [float(x) for x in list(final_gdsc_rna_df[cellline_name])]\n",
    "            gene_cnv_list = [float(x) for x in list(final_gdsc_cnv_df[cellline_name])]\n",
    "            # COMBINE [drugA, drugB, rna, cmeth] \n",
    "            x_input_list = []\n",
    "            for i in range(num_gene):\n",
    "                # APPEND DRUG INFORMATION\n",
    "                x_input_list.append(one_drug_target_list[i])\n",
    "                x_input_list.append(duo_drug_target_list[i])\n",
    "                # APPEND GENE FEATURES\n",
    "                x_input_list.append(gene_rna_list[i])\n",
    "                x_input_list.append(gene_cnv_list[i])\n",
    "            if drug_feature == False:\n",
    "                fillin_list = [0.0] * num_feature\n",
    "                for i in range(num_drug):\n",
    "                    x_input_list += fillin_list\n",
    "            x_input = np.array(x_input_list)\n",
    "            x_batch = np.vstack((x_batch, x_input))\n",
    "            # COMBINE DRUG[A/B] LIST\n",
    "            drug_input_list.append(drug_dict[drug_a])\n",
    "            drug_input_list.append(drug_dict[drug_b])\n",
    "            # COMBINE SCORE LIST\n",
    "            y_input_list.append(y)\n",
    "        # import pdb; pdb.set_trace()\n",
    "        x_batch = np.delete(x_batch, 0, axis = 0)\n",
    "        y_batch = np.array(y_input_list).reshape(tmp_batch_size, 1)\n",
    "        drug_batch = np.array(drug_input_list).reshape(tmp_batch_size, 2)\n",
    "        print(x_batch.shape)\n",
    "        print(y_batch.shape)\n",
    "        print(drug_batch.shape)\n",
    "        return x_batch, y_batch, drug_batch\n",
    "\n",
    "\n",
    "    def load_all_split(self, batch_size, k):\n",
    "        form_data_path = './' + self.dataset+ '/form_data'\n",
    "        # LOAD 100 PERCENT DATA\n",
    "        print('LOADING ALL SPLIT DATA...')\n",
    "        # FIRST LOAD EACH SPLIT DATA\n",
    "        for place_num in range(k):\n",
    "            split_input_df = pd.read_csv('./' + self.dataset+ '/filtered_data/split_input_' + str(place_num + 1) + '.csv')\n",
    "            input_num, input_dim = split_input_df.shape\n",
    "            num_feature = 4\n",
    "            final_annotation_gene_df = pd.read_csv('./' + self.dataset+ '/filtered_data/kegg_gene_annotation.csv')\n",
    "            gene_name_list = list(final_annotation_gene_df['kegg_gene'])\n",
    "            num_gene = len(gene_name_list)\n",
    "            drug_num_dict_df = pd.read_csv('./' + self.dataset+ '/filtered_data/drug_num_dict.csv')\n",
    "            drug_dict = dict(zip(drug_num_dict_df.Drug, drug_num_dict_df.drug_num))\n",
    "            num_drug = len(drug_dict)\n",
    "            x_split = np.zeros((1, num_feature * (num_gene + num_drug)))\n",
    "            y_split = np.zeros((1, 1))\n",
    "            drug_split = np.zeros((1, 2))\n",
    "            for index in range(0, input_num, batch_size):\n",
    "                if (index + batch_size) < input_num:\n",
    "                    upper_index = index + batch_size\n",
    "                else:\n",
    "                    upper_index = input_num\n",
    "                    datset = self.dataset\n",
    "                x_batch, y_batch, drug_batch = LoadData(dataset).load_batch(index, upper_index, place_num)\n",
    "                x_split = np.vstack((x_split, x_batch))\n",
    "                y_split = np.vstack((y_split, y_batch))\n",
    "                drug_split = np.vstack((drug_split, drug_batch))\n",
    "            x_split = np.delete(x_split, 0, axis = 0)\n",
    "            y_split = np.delete(y_split, 0, axis = 0)\n",
    "            drug_split = np.delete(drug_split, 0, axis = 0)\n",
    "            print('-------SPLIT DATA SHAPE-------')\n",
    "            print(x_split.shape)\n",
    "            print(y_split.shape)\n",
    "            print(drug_split.shape)\n",
    "            np.save(form_data_path + '/x_split' + str(place_num + 1) + '.npy', x_split)\n",
    "            np.save(form_data_path + '/y_split' + str(place_num + 1) + '.npy', y_split)\n",
    "            np.save(form_data_path + '/drug_split' + str(place_num + 1) + '.npy', drug_split)\n",
    "            \n",
    "\n",
    "    def load_train_test(self, k, n_fold):\n",
    "        form_data_path = './' + self.dataset+ '/form_data'\n",
    "        num_feature = 4\n",
    "        final_annotation_gene_df = pd.read_csv('./' + self.dataset+ '/filtered_data/kegg_gene_annotation.csv')\n",
    "        gene_name_list = list(final_annotation_gene_df['kegg_gene'])\n",
    "        num_gene = len(gene_name_list)\n",
    "        drug_num_dict_df = pd.read_csv('./' + self.dataset+ '/filtered_data/drug_num_dict.csv')\n",
    "        drug_dict = dict(zip(drug_num_dict_df.Drug, drug_num_dict_df.drug_num))\n",
    "        num_drug = len(drug_dict)\n",
    "        xTr = np.zeros((1, num_feature * (num_gene + num_drug)))\n",
    "        yTr = np.zeros((1, 1))\n",
    "        drugTr = np.zeros((1, 2))\n",
    "        for i in range(1, k + 1):\n",
    "            if i == n_fold:\n",
    "                print('--- LOADING ' + str(i) + '-TH SPLIT TEST DATA ---')\n",
    "                xTe = np.load(form_data_path + '/x_split' + str(i) + '.npy')\n",
    "                yTe = np.load(form_data_path + '/y_split' + str(i) + '.npy')\n",
    "                drugTe = np.load(form_data_path + '/drug_split' + str(i) + '.npy')\n",
    "            else:\n",
    "                print('--- LOADING ' + str(i) + '-TH SPLIT TRAINING DATA ---')\n",
    "                x_split = np.load(form_data_path + '/x_split' + str(i) + '.npy')\n",
    "                y_split = np.load(form_data_path + '/y_split' + str(i) + '.npy')\n",
    "                drug_split = np.load(form_data_path + '/drug_split' + str(i) + '.npy')\n",
    "                print('--- COMBINING DATA ... ---')\n",
    "                xTr = np.vstack((xTr, x_split))\n",
    "                yTr = np.vstack((yTr, y_split))\n",
    "                drugTr = np.vstack((drugTr, drug_split))\n",
    "        print('--- TRAINING INPUT SHAPE ---')\n",
    "        xTr = np.delete(xTr, 0, axis = 0)\n",
    "        yTr = np.delete(yTr, 0, axis = 0)\n",
    "        drugTr = np.delete(drugTr, 0, axis = 0)\n",
    "        print(xTr.shape)\n",
    "        print(yTr.shape)\n",
    "        print(drugTr.shape)\n",
    "        np.save(form_data_path + '/xTr' + str(n_fold) + '.npy', xTr)\n",
    "        np.save(form_data_path + '/yTr' + str(n_fold) + '.npy', yTr)\n",
    "        np.save(form_data_path + '/drugTr' + str(n_fold) + '.npy', drugTr)\n",
    "        print('--- TEST INPUT SHAPE ---')\n",
    "        print(xTe.shape)\n",
    "        print(yTe.shape)\n",
    "        print(drugTe.shape)\n",
    "        np.save(form_data_path + '/xTe' + str(n_fold) + '.npy', xTe)\n",
    "        np.save(form_data_path + '/yTe' + str(n_fold) + '.npy', yTe)\n",
    "        np.save(form_data_path + '/drugTe' + str(n_fold) + '.npy', drugTe)\n",
    "\n",
    "    def combine_whole_dataset(self, k):\n",
    "        form_data_path = './' + self.dataset+ '/form_data'\n",
    "        num_feature = 4\n",
    "        final_annotation_gene_df = pd.read_csv('./' + self.dataset+ '/filtered_data/kegg_gene_annotation.csv')\n",
    "        gene_name_list = list(final_annotation_gene_df['kegg_gene'])\n",
    "        num_gene = len(gene_name_list)\n",
    "        drug_num_dict_df = pd.read_csv('./' + self.dataset+ '/filtered_data/drug_num_dict.csv')\n",
    "        drug_dict = dict(zip(drug_num_dict_df.Drug, drug_num_dict_df.drug_num))\n",
    "        num_drug = len(drug_dict)\n",
    "        xAll = np.zeros((1, num_feature * (num_gene + num_drug)))\n",
    "        yAll = np.zeros((1, 1))\n",
    "        drugAll = np.zeros((1, 2))\n",
    "        for i in range(1, k + 1):\n",
    "            print('--- LOADING ' + str(i) + '-TH SPLIT TRAINING DATA ---')\n",
    "            x_split = np.load(form_data_path + '/x_split' + str(i) + '.npy')\n",
    "            y_split = np.load(form_data_path + '/y_split' + str(i) + '.npy')\n",
    "            drug_split = np.load(form_data_path + '/drug_split' + str(i) + '.npy')\n",
    "            print('--- COMBINING DATA ... ---')\n",
    "            xAll = np.vstack((xAll, x_split))\n",
    "            yAll = np.vstack((yAll, y_split))\n",
    "            drugAll = np.vstack((drugAll, drug_split))\n",
    "        print('--- ALL DATASET INPUT SHAPE ---')\n",
    "        xAll = np.delete(xAll, 0, axis = 0)\n",
    "        yAll = np.delete(yAll, 0, axis = 0)\n",
    "        drugAll = np.delete(drugAll, 0, axis = 0)\n",
    "        print(xAll.shape)\n",
    "        print(yAll.shape)\n",
    "        print(drugAll.shape)\n",
    "        np.save(form_data_path + '/xAll.npy', xAll)\n",
    "        np.save(form_data_path + '/yAll.npy', yAll)\n",
    "        np.save(form_data_path + '/drugAll.npy', drugAll)\n",
    "    \n",
    "    def load_adj_edgeindex(self):\n",
    "        form_data_path = './' + self.dataset+ '/form_data'\n",
    "        # FORM A WHOLE ADJACENT MATRIX\n",
    "        gene_num_df = pd.read_csv('./' + self.dataset+ '/filtered_data/kegg_gene_num_interaction.csv')\n",
    "        src_gene_list = list(gene_num_df['src'])\n",
    "        dest_gene_list = list(gene_num_df['dest'])\n",
    "        final_annotation_gene_df = pd.read_csv('./' + self.dataset+ '/filtered_data/kegg_gene_annotation.csv')\n",
    "        gene_name_list = list(final_annotation_gene_df['kegg_gene'])\n",
    "        num_gene = len(gene_name_list)\n",
    "        dict_drug_num = pd.read_csv('./' + self.dataset+ '/filtered_data/drug_num_dict.csv')\n",
    "        num_drug = dict_drug_num.shape[0]\n",
    "        num_node = num_gene + num_drug\n",
    "        adj = np.zeros((num_node, num_node))\n",
    "        # GENE-GENE ADJACENT MATRIX\n",
    "        for i in range(len(src_gene_list)):\n",
    "            row_idx = src_gene_list[i] - 1\n",
    "            col_idx = dest_gene_list[i] - 1\n",
    "            adj[row_idx, col_idx] = 1\n",
    "            adj[col_idx, row_idx] = 1 # WHETHER WE WANT ['sym']\n",
    "        # import pdb; pdb.set_trace()\n",
    "        # DRUG_TARGET ADJACENT MATRIX\n",
    "        drugbank_num_df = pd.read_csv('./' + self.dataset+ '/filtered_data/final_drugbank_num.csv')\n",
    "        drugbank_drug_list = list(drugbank_num_df['Drug'])\n",
    "        drugbank_target_list = list(drugbank_num_df['Target'])\n",
    "        for row in drugbank_num_df.itertuples():\n",
    "            row_idx = row[1] - 1\n",
    "            col_idx = row[2] - 1\n",
    "            adj[row_idx, col_idx] = 1\n",
    "            adj[col_idx, row_idx] = 1\n",
    "        # import pdb; pdb.set_trace()\n",
    "        # np.save(form_data_path + '/adj.npy', adj)\n",
    "        adj_sparse = sparse.csr_matrix(adj)\n",
    "        sparse.save_npz(form_data_path + '/adj_sparse.npz', adj_sparse)\n",
    "        # [edge_index]\n",
    "        genedrug_src_list = src_gene_list + drugbank_drug_list + drugbank_target_list\n",
    "        genedrug_dest_list = dest_gene_list + drugbank_target_list + drugbank_drug_list\n",
    "        genedrug_src_indexlist = []\n",
    "        genedrug_dest_indexlist = []\n",
    "        for i in range(len(genedrug_src_list)):\n",
    "            genedrug_src_index = genedrug_src_list[i] - 1\n",
    "            genedrug_src_indexlist.append(genedrug_src_index)\n",
    "            genedrug_dest_index = genedrug_dest_list[i] - 1\n",
    "            genedrug_dest_indexlist.append(genedrug_dest_index)\n",
    "        edge_index = np.column_stack((genedrug_src_indexlist, genedrug_dest_indexlist)).T\n",
    "        np.save(form_data_path + '/edge_index.npy', edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e390b472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOMIZE THE [final_NCI60_DeepLearningInput]\n",
    "def input_random(dataset):\n",
    "    final_input_df = pd.read_csv('./' + dataset + '/filtered_data/final_dl_input.csv')\n",
    "    random_final_input_df = final_input_df.sample(frac = 1)\n",
    "    random_final_input_df.to_csv('./' + dataset + '/filtered_data/random_final_dl_input.csv', index = False, header = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95596104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT DEEP LEARNING INPUT INTO TRAINING AND TEST\n",
    "def split_k_fold(k, dataset):\n",
    "    random_final_dl_input_df = pd.read_csv('./' + dataset + '/filtered_data/random_final_dl_input.csv')\n",
    "    num_points = random_final_dl_input_df.shape[0]\n",
    "    num_div = int(num_points / k)\n",
    "    num_div_list = [i * num_div for i in range(0, k)]\n",
    "    num_div_list.append(num_points)\n",
    "    # SPLIT [RandomFinal_NCI60_DeepLearningInput] INTO [k] FOLDS\n",
    "    for place_num in range(k):\n",
    "        low_idx = num_div_list[place_num]\n",
    "        high_idx = num_div_list[place_num + 1]\n",
    "        print('\\n--------TRAIN-TEST SPLIT WITH TEST FROM ' + str(low_idx) + ' TO ' + str(high_idx) + '--------')\n",
    "        split_input_df = random_final_dl_input_df[low_idx : high_idx]\n",
    "        split_input_df.to_csv('./' + dataset + '/filtered_data/split_input_' + str(place_num + 1) + '.csv', index = False, header = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459c902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ############## MOUDLE 1 ################\n",
    "k = 2\n",
    "# DATASET SELECTION\n",
    "dataset = 'data-drugcomb-fi'\n",
    "# dataset = 'data-DrugCombDB'\n",
    "# dataset = 'data-nci'\n",
    "# dataset = 'data-oneil'\n",
    "\n",
    "# input_random(dataset)\n",
    "# split_k_fold(k, dataset)\n",
    "\n",
    "if os.path.exists('./' + dataset + '/form_data') == False:\n",
    "    os.mkdir('./' + dataset + '/form_data')\n",
    "batch_size = 64\n",
    "LoadData(dataset).load_all_split(batch_size, k)\n",
    "\n",
    "n_fold = 2\n",
    "# ############## MOUDLE 2 ################\n",
    "print('split_input_' + str(n_fold) + '.csv')\n",
    "LoadData(dataset).load_adj_edgeindex()\n",
    "\n",
    "################ MOUDLE 3 ################\n",
    "# FORM N-TH FOLD TRAINING DATASET\n",
    "LoadData(dataset).load_train_test(k, n_fold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
