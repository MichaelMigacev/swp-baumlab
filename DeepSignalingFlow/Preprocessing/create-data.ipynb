{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c023612b",
   "metadata": {},
   "source": [
    "# Generate Training Data\n",
    "\n",
    "Let's randomize our data and generate new splits as mentioned in `preprocessing.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d05ea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import inf\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4efea3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to do a 5 split 5 fold validation just like in the paper\n",
    "k = 5\n",
    "n_fold = 5\n",
    "\n",
    "# DATASET SELECTION\n",
    "# dataset = 'data-drugcomb-fi'\n",
    "# dataset = 'data-DrugCombDB'\n",
    "dataset = 'data-nci'\n",
    "# dataset = 'data-oneil'\n",
    "\n",
    "# TARGET FOLDER\n",
    "if os.path.exists('../' + dataset + '/form_data') == False:\n",
    "    os.mkdir('../' + dataset + '/form_data')\n",
    "\n",
    "#BATCH SIZE\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "#LoadData(dataset).load_all_split(batch_size, k)\n",
    "\n",
    "\n",
    "# ############## MOUDLE 2 ################\n",
    "#print('split_input_' + str(n_fold) + '.csv')\n",
    "#LoadData(dataset).load_adj_edgeindex()\n",
    "\n",
    "############### MOUDLE 3 ################\n",
    "# FORM N-TH FOLD TRAINING DATASET\n",
    "#LoadData(dataset).load_train_test(k, n_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6519954",
   "metadata": {},
   "source": [
    "We modify the paths to fit into our structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac39c538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOMIZE THE [final_NCI60_DeepLearningInput]\n",
    "def input_random(dataset):\n",
    "    final_input_df = pd.read_csv('../' + dataset + '/filtered_data/final_dl_input.csv')\n",
    "    random_final_input_df = final_input_df.sample(frac = 1)\n",
    "    random_final_input_df.to_csv('../' + dataset + '/filtered_data/random_final_dl_input.csv', index = False, header = True)\n",
    "\n",
    "# SPLIT DEEP LEARNING INPUT INTO TRAINING AND TEST\n",
    "def split_k_fold(k, dataset):\n",
    "    random_final_dl_input_df = pd.read_csv('../' + dataset + '/filtered_data/random_final_dl_input.csv')\n",
    "    num_points = random_final_dl_input_df.shape[0]\n",
    "    num_div = int(num_points / k)\n",
    "    num_div_list = [i * num_div for i in range(0, k)]\n",
    "    num_div_list.append(num_points)\n",
    "    # SPLIT [RandomFinal_NCI60_DeepLearningInput] INTO [k] FOLDS\n",
    "    for place_num in range(k):\n",
    "        low_idx = num_div_list[place_num]\n",
    "        high_idx = num_div_list[place_num + 1]\n",
    "        print('\\n--------TRAIN-TEST SPLIT WITH TEST FROM ' + str(low_idx) + ' TO ' + str(high_idx) + '--------')\n",
    "        split_input_df = random_final_dl_input_df[low_idx : high_idx]\n",
    "        split_input_df.to_csv('../' + dataset + '/filtered_data/split_input_' + str(place_num + 1) + '.csv', index = False, header = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd83a087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------TRAIN-TEST SPLIT WITH TEST FROM 0 TO 788--------\n",
      "\n",
      "--------TRAIN-TEST SPLIT WITH TEST FROM 788 TO 1576--------\n",
      "\n",
      "--------TRAIN-TEST SPLIT WITH TEST FROM 1576 TO 2364--------\n",
      "\n",
      "--------TRAIN-TEST SPLIT WITH TEST FROM 2364 TO 3152--------\n",
      "\n",
      "--------TRAIN-TEST SPLIT WITH TEST FROM 3152 TO 3942--------\n"
     ]
    }
   ],
   "source": [
    "# RUN ONLY once per Dataset\n",
    "input_random(dataset)\n",
    "split_k_fold(k, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b40ee15",
   "metadata": {},
   "source": [
    "### Now we import the class, so we can stay more true to the paper and disect the individual functions below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a857fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadData():\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        pass\n",
    "\n",
    "    def load_batch(self, index, upper_index, place_num, drug_feature=False):\n",
    "        # PRELOAD EACH SPLIT DATASET\n",
    "        split_input_df = pd.read_csv('../' + self.dataset+ '/filtered_data/split_input_' + str(place_num + 1) + '.csv')\n",
    "        num_feature = 4\n",
    "        final_annotation_gene_df = pd.read_csv('../' + self.dataset+ '/filtered_data/kegg_gene_annotation.csv')\n",
    "        gene_name_list = list(final_annotation_gene_df['kegg_gene'])\n",
    "        print('READING GENE FEATURES FILES ...')\n",
    "        final_gdsc_rna_df = pd.read_csv('../' + self.dataset+ '/filtered_data/final_rna.csv')\n",
    "        final_gdsc_cnv_df = pd.read_csv('../' + self.dataset+ '/filtered_data/final_cnv.csv')\n",
    "        num_gene, num_cellline = final_gdsc_rna_df.shape\n",
    "        # CONVERT [drugbank.csv] TO A LIST\n",
    "        print('READING DRUGBANK ...')\n",
    "        final_drugbank_df = pd.read_csv('../' + self.dataset+ '/filtered_data/final_drugbank.csv')\n",
    "        final_drugbank_comlist = final_drugbank_df.values.tolist()\n",
    "        print('READING DRUGDICT ...')\n",
    "        drug_num_dict_df = pd.read_csv('../' + self.dataset+ '/filtered_data/drug_num_dict.csv')\n",
    "        drug_dict = dict(zip(drug_num_dict_df.Drug, drug_num_dict_df.drug_num))\n",
    "        num_drug = len(drug_dict)\n",
    "        print('READING FINISHED ...')\n",
    "        # COMBINE A BATCH SIZE AS [x_batch, y_batch, drug_batch]\n",
    "        print('-----' + str(index) + ' to ' + str(upper_index) + '-----')\n",
    "        tmp_batch_size = 0\n",
    "        y_input_list = []\n",
    "        drug_input_list = []\n",
    "        x_batch = np.zeros((1, (num_feature * (num_gene + num_drug))))\n",
    "        for row in split_input_df.iloc[index : upper_index].itertuples():\n",
    "            tmp_batch_size += 1\n",
    "            drug_a = row[1]\n",
    "            drug_b = row[2]\n",
    "            cellline_name = row[3]\n",
    "            if dataset == 'data-drugcomb-fi':\n",
    "                y = row[5]\n",
    "            else:\n",
    "                y = row[4]\n",
    "            # DRUG_A AND [4853] TARGET GENES\n",
    "            one_drug_target_list = []\n",
    "            duo_drug_target_list = []\n",
    "            for gene in gene_name_list:\n",
    "                drugA_target = [drug_a, gene] in final_drugbank_comlist\n",
    "                drugB_target = [drug_b, gene] in final_drugbank_comlist\n",
    "                if drugA_target and drugB_target:\n",
    "                    one_drug_target_list.append(0.0)\n",
    "                    duo_drug_target_list.append(1.0)\n",
    "                elif drugA_target or drugB_target:\n",
    "                    one_drug_target_list.append(1.0)\n",
    "                    duo_drug_target_list.append(0.0)\n",
    "                else:\n",
    "                    one_drug_target_list.append(0.0)\n",
    "                    duo_drug_target_list.append(0.0)\n",
    "            # GENE FEATURES SEQUENCE\n",
    "            gene_rna_list = [float(x) for x in list(final_gdsc_rna_df[cellline_name])]\n",
    "            gene_cnv_list = [float(x) for x in list(final_gdsc_cnv_df[cellline_name])]\n",
    "            # COMBINE [drugA, drugB, rna, cmeth] \n",
    "            x_input_list = []\n",
    "            for i in range(num_gene):\n",
    "                # APPEND DRUG INFORMATION\n",
    "                x_input_list.append(one_drug_target_list[i])\n",
    "                x_input_list.append(duo_drug_target_list[i])\n",
    "                # APPEND GENE FEATURES\n",
    "                x_input_list.append(gene_rna_list[i])\n",
    "                x_input_list.append(gene_cnv_list[i])\n",
    "            if drug_feature == False:\n",
    "                fillin_list = [0.0] * num_feature\n",
    "                for i in range(num_drug):\n",
    "                    x_input_list += fillin_list\n",
    "            x_input = np.array(x_input_list)\n",
    "            x_batch = np.vstack((x_batch, x_input))\n",
    "            # COMBINE DRUG[A/B] LIST\n",
    "            drug_input_list.append(drug_dict[drug_a])\n",
    "            drug_input_list.append(drug_dict[drug_b])\n",
    "            # COMBINE SCORE LIST\n",
    "            y_input_list.append(y)\n",
    "        # import pdb; pdb.set_trace()\n",
    "        x_batch = np.delete(x_batch, 0, axis = 0)\n",
    "        y_batch = np.array(y_input_list).reshape(tmp_batch_size, 1)\n",
    "        drug_batch = np.array(drug_input_list).reshape(tmp_batch_size, 2)\n",
    "        print(x_batch.shape)\n",
    "        print(y_batch.shape)\n",
    "        print(drug_batch.shape)\n",
    "        return x_batch, y_batch, drug_batch\n",
    "\n",
    "\n",
    "    def load_all_split(self, batch_size, k):\n",
    "        form_data_path = '../' + self.dataset+ '/form_data'\n",
    "        # LOAD 100 PERCENT DATA\n",
    "        print('LOADING ALL SPLIT DATA...')\n",
    "        # FIRST LOAD EACH SPLIT DATA\n",
    "        for place_num in range(k):\n",
    "            split_input_df = pd.read_csv('../' + self.dataset+ '/filtered_data/split_input_' + str(place_num + 1) + '.csv')\n",
    "            input_num, input_dim = split_input_df.shape\n",
    "            num_feature = 4\n",
    "            final_annotation_gene_df = pd.read_csv('../' + self.dataset+ '/filtered_data/kegg_gene_annotation.csv')\n",
    "            gene_name_list = list(final_annotation_gene_df['kegg_gene'])\n",
    "            num_gene = len(gene_name_list)\n",
    "            drug_num_dict_df = pd.read_csv('../' + self.dataset+ '/filtered_data/drug_num_dict.csv')\n",
    "            drug_dict = dict(zip(drug_num_dict_df.Drug, drug_num_dict_df.drug_num))\n",
    "            num_drug = len(drug_dict)\n",
    "            x_split = np.zeros((1, num_feature * (num_gene + num_drug)))\n",
    "            y_split = np.zeros((1, 1))\n",
    "            drug_split = np.zeros((1, 2))\n",
    "            for index in range(0, input_num, batch_size):\n",
    "                if (index + batch_size) < input_num:\n",
    "                    upper_index = index + batch_size\n",
    "                else:\n",
    "                    upper_index = input_num\n",
    "                    dataset = self.dataset # TYPO IN ORIGINAL REPO\n",
    "                x_batch, y_batch, drug_batch = LoadData(dataset).load_batch(index, upper_index, place_num)\n",
    "                x_split = np.vstack((x_split, x_batch))\n",
    "                y_split = np.vstack((y_split, y_batch))\n",
    "                drug_split = np.vstack((drug_split, drug_batch))\n",
    "            x_split = np.delete(x_split, 0, axis = 0)\n",
    "            y_split = np.delete(y_split, 0, axis = 0)\n",
    "            drug_split = np.delete(drug_split, 0, axis = 0)\n",
    "            print('-------SPLIT DATA SHAPE-------')\n",
    "            print(x_split.shape)\n",
    "            print(y_split.shape)\n",
    "            print(drug_split.shape)\n",
    "            np.save(form_data_path + '/x_split' + str(place_num + 1) + '.npy', x_split)\n",
    "            np.save(form_data_path + '/y_split' + str(place_num + 1) + '.npy', y_split)\n",
    "            np.save(form_data_path + '/drug_split' + str(place_num + 1) + '.npy', drug_split)\n",
    "            \n",
    "\n",
    "    def load_train_test(self, k, n_fold):\n",
    "        form_data_path = '../' + self.dataset+ '/form_data'\n",
    "        num_feature = 4\n",
    "        final_annotation_gene_df = pd.read_csv('../' + self.dataset+ '/filtered_data/kegg_gene_annotation.csv')\n",
    "        gene_name_list = list(final_annotation_gene_df['kegg_gene'])\n",
    "        num_gene = len(gene_name_list)\n",
    "        drug_num_dict_df = pd.read_csv('../' + self.dataset+ '/filtered_data/drug_num_dict.csv')\n",
    "        drug_dict = dict(zip(drug_num_dict_df.Drug, drug_num_dict_df.drug_num))\n",
    "        num_drug = len(drug_dict)\n",
    "        xTr = np.zeros((1, num_feature * (num_gene + num_drug)))\n",
    "        yTr = np.zeros((1, 1))\n",
    "        drugTr = np.zeros((1, 2))\n",
    "        for i in range(1, k + 1):\n",
    "            if i == n_fold:\n",
    "                print('--- LOADING ' + str(i) + '-TH SPLIT TEST DATA ---')\n",
    "                xTe = np.load(form_data_path + '/x_split' + str(i) + '.npy')\n",
    "                yTe = np.load(form_data_path + '/y_split' + str(i) + '.npy')\n",
    "                drugTe = np.load(form_data_path + '/drug_split' + str(i) + '.npy')\n",
    "            else:\n",
    "                print('--- LOADING ' + str(i) + '-TH SPLIT TRAINING DATA ---')\n",
    "                x_split = np.load(form_data_path + '/x_split' + str(i) + '.npy')\n",
    "                y_split = np.load(form_data_path + '/y_split' + str(i) + '.npy')\n",
    "                drug_split = np.load(form_data_path + '/drug_split' + str(i) + '.npy')\n",
    "                print('--- COMBINING DATA ... ---')\n",
    "                xTr = np.vstack((xTr, x_split))\n",
    "                yTr = np.vstack((yTr, y_split))\n",
    "                drugTr = np.vstack((drugTr, drug_split))\n",
    "        print('--- TRAINING INPUT SHAPE ---')\n",
    "        xTr = np.delete(xTr, 0, axis = 0)\n",
    "        yTr = np.delete(yTr, 0, axis = 0)\n",
    "        drugTr = np.delete(drugTr, 0, axis = 0)\n",
    "        print(xTr.shape)\n",
    "        print(yTr.shape)\n",
    "        print(drugTr.shape)\n",
    "        np.save(form_data_path + '/xTr' + str(n_fold) + '.npy', xTr)\n",
    "        np.save(form_data_path + '/yTr' + str(n_fold) + '.npy', yTr)\n",
    "        np.save(form_data_path + '/drugTr' + str(n_fold) + '.npy', drugTr)\n",
    "        print('--- TEST INPUT SHAPE ---')\n",
    "        print(xTe.shape)\n",
    "        print(yTe.shape)\n",
    "        print(drugTe.shape)\n",
    "        np.save(form_data_path + '/xTe' + str(n_fold) + '.npy', xTe)\n",
    "        np.save(form_data_path + '/yTe' + str(n_fold) + '.npy', yTe)\n",
    "        np.save(form_data_path + '/drugTe' + str(n_fold) + '.npy', drugTe)\n",
    "\n",
    "    def combine_whole_dataset(self, k):\n",
    "        form_data_path = '../' + self.dataset+ '/form_data'\n",
    "        num_feature = 4\n",
    "        final_annotation_gene_df = pd.read_csv('../' + self.dataset+ '/filtered_data/kegg_gene_annotation.csv')\n",
    "        gene_name_list = list(final_annotation_gene_df['kegg_gene'])\n",
    "        num_gene = len(gene_name_list)\n",
    "        drug_num_dict_df = pd.read_csv('../' + self.dataset+ '/filtered_data/drug_num_dict.csv')\n",
    "        drug_dict = dict(zip(drug_num_dict_df.Drug, drug_num_dict_df.drug_num))\n",
    "        num_drug = len(drug_dict)\n",
    "        xAll = np.zeros((1, num_feature * (num_gene + num_drug)))\n",
    "        yAll = np.zeros((1, 1))\n",
    "        drugAll = np.zeros((1, 2))\n",
    "        for i in range(1, k + 1):\n",
    "            print('--- LOADING ' + str(i) + '-TH SPLIT TRAINING DATA ---')\n",
    "            x_split = np.load(form_data_path + '/x_split' + str(i) + '.npy')\n",
    "            y_split = np.load(form_data_path + '/y_split' + str(i) + '.npy')\n",
    "            drug_split = np.load(form_data_path + '/drug_split' + str(i) + '.npy')\n",
    "            print('--- COMBINING DATA ... ---')\n",
    "            xAll = np.vstack((xAll, x_split))\n",
    "            yAll = np.vstack((yAll, y_split))\n",
    "            drugAll = np.vstack((drugAll, drug_split))\n",
    "        print('--- ALL DATASET INPUT SHAPE ---')\n",
    "        xAll = np.delete(xAll, 0, axis = 0)\n",
    "        yAll = np.delete(yAll, 0, axis = 0)\n",
    "        drugAll = np.delete(drugAll, 0, axis = 0)\n",
    "        print(xAll.shape)\n",
    "        print(yAll.shape)\n",
    "        print(drugAll.shape)\n",
    "        np.save(form_data_path + '/xAll.npy', xAll)\n",
    "        np.save(form_data_path + '/yAll.npy', yAll)\n",
    "        np.save(form_data_path + '/drugAll.npy', drugAll)\n",
    "    \n",
    "    def load_adj_edgeindex(self):\n",
    "        form_data_path = '../' + self.dataset+ '/form_data'\n",
    "        # FORM A WHOLE ADJACENT MATRIX\n",
    "        gene_num_df = pd.read_csv('../' + self.dataset+ '/filtered_data/kegg_gene_num_interaction.csv')\n",
    "        src_gene_list = list(gene_num_df['src'])\n",
    "        dest_gene_list = list(gene_num_df['dest'])\n",
    "        final_annotation_gene_df = pd.read_csv('../' + self.dataset+ '/filtered_data/kegg_gene_annotation.csv')\n",
    "        gene_name_list = list(final_annotation_gene_df['kegg_gene'])\n",
    "        num_gene = len(gene_name_list)\n",
    "        dict_drug_num = pd.read_csv('../' + self.dataset+ '/filtered_data/drug_num_dict.csv')\n",
    "        num_drug = dict_drug_num.shape[0]\n",
    "        num_node = num_gene + num_drug\n",
    "        adj = np.zeros((num_node, num_node))\n",
    "        # GENE-GENE ADJACENT MATRIX\n",
    "        for i in range(len(src_gene_list)):\n",
    "            row_idx = src_gene_list[i] - 1\n",
    "            col_idx = dest_gene_list[i] - 1\n",
    "            adj[row_idx, col_idx] = 1\n",
    "            adj[col_idx, row_idx] = 1 # WHETHER WE WANT ['sym']\n",
    "        # import pdb; pdb.set_trace()\n",
    "        # DRUG_TARGET ADJACENT MATRIX\n",
    "        drugbank_num_df = pd.read_csv('../' + self.dataset+ '/filtered_data/final_drugbank_num.csv')\n",
    "        drugbank_drug_list = list(drugbank_num_df['Drug'])\n",
    "        drugbank_target_list = list(drugbank_num_df['Target'])\n",
    "        for row in drugbank_num_df.itertuples():\n",
    "            row_idx = row[1] - 1\n",
    "            col_idx = row[2] - 1\n",
    "            adj[row_idx, col_idx] = 1\n",
    "            adj[col_idx, row_idx] = 1\n",
    "        # import pdb; pdb.set_trace()\n",
    "        # np.save(form_data_path + '/adj.npy', adj)\n",
    "        adj_sparse = sparse.csr_matrix(adj)\n",
    "        sparse.save_npz(form_data_path + '/adj_sparse.npz', adj_sparse)\n",
    "        # [edge_index]\n",
    "        genedrug_src_list = src_gene_list + drugbank_drug_list + drugbank_target_list\n",
    "        genedrug_dest_list = dest_gene_list + drugbank_target_list + drugbank_drug_list\n",
    "        genedrug_src_indexlist = []\n",
    "        genedrug_dest_indexlist = []\n",
    "        for i in range(len(genedrug_src_list)):\n",
    "            genedrug_src_index = genedrug_src_list[i] - 1\n",
    "            genedrug_src_indexlist.append(genedrug_src_index)\n",
    "            genedrug_dest_index = genedrug_dest_list[i] - 1\n",
    "            genedrug_dest_indexlist.append(genedrug_dest_index)\n",
    "        edge_index = np.column_stack((genedrug_src_indexlist, genedrug_dest_indexlist)).T\n",
    "        np.save(form_data_path + '/edge_index.npy', edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cea75a",
   "metadata": {},
   "source": [
    "#### The first function that is called is, `load_all_split`, which calls `load_batch`\n",
    "\n",
    "So first taking a look at load batch:\n",
    "\n",
    "```python\n",
    "def load_batch(self, index, upper_index, place_num, drug_feature=False):\n",
    "        ###########\n",
    "        #CODE\n",
    "        ###########\n",
    "        return x_batch, y_batch, drug_batch\n",
    "```\n",
    "\n",
    "`load_batch` takes in `index` (number that we start with), an end `upper_index` (number that we end with) <br> \n",
    "and a `place_num` (number of split we are in) as well as `drug_feature` to see if we need to fill in values <br>\n",
    "The output is the our inputs `x_batch` our targets `y_batch` as well as the corresponding input drug list `drug_batch` <br> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c464e3e",
   "metadata": {},
   "source": [
    "Let's go over this step by step and pretend we call our function <br>\n",
    "`load_batch(index=0, upper_index=64, place_num=0, drug_feature=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e87e0df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input\n",
    "index = 0\n",
    "upper_index = 64\n",
    "place_num = 0\n",
    "drug_feature=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bea77b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRELOAD EACH SPLIT DATASET\n",
    "split_input_df = pd.read_csv('../' + dataset+ '/filtered_data/split_input_' + str(place_num + 1) + '.csv')\n",
    "num_feature = 4\n",
    "# LOAD ANNOTATIONS\n",
    "final_annotation_gene_df = pd.read_csv('../' + dataset + '/filtered_data/kegg_gene_annotation.csv')\n",
    "gene_name_list = list(final_annotation_gene_df['kegg_gene'])\n",
    "# LOAD RNA and CNA (multi-omic data) FOR EACH GENE based on CELLLINE\n",
    "final_gdsc_rna_df = pd.read_csv('../' + dataset+ '/filtered_data/final_rna.csv')\n",
    "final_gdsc_cnv_df = pd.read_csv('../' + dataset+ '/filtered_data/final_cnv.csv')\n",
    "num_gene, num_cellline = final_gdsc_rna_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9653782a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING FINISHED ...\n"
     ]
    }
   ],
   "source": [
    "# CONVERT [drugbank.csv] TO A LIST\n",
    "# CONTAINS DRUGS AND THEIR TARGETS\n",
    "final_drugbank_df = pd.read_csv('../' + dataset+ '/filtered_data/final_drugbank.csv')\n",
    "final_drugbank_comlist = final_drugbank_df.values.tolist()\n",
    "# LOAD DRUGDICT (Drug and Number of Drug) AND MAKE DICT\n",
    "drug_num_dict_df = pd.read_csv('../' + dataset+ '/filtered_data/drug_num_dict.csv')\n",
    "drug_dict = dict(zip(drug_num_dict_df.Drug, drug_num_dict_df.drug_num))\n",
    "num_drug = len(drug_dict)\n",
    "print('READING FINISHED ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a732fcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Celecoxib': 2017, 'Cladribine': 2018, 'Dasatinib': 2019, 'Docetaxel': 2020, 'Everolimus': 2021, 'Fulvestrant': 2022, 'Gefitinib': 2023, 'Lenalidomide': 2024, 'Megestrol acetate': 2025, 'Mitotane': 2026, 'Nilotinib': 2027, 'Paclitaxel': 2028, 'Romidepsin': 2029, 'Sirolimus': 2030, 'Streptozocin': 2031, 'Thalidomide': 2032, 'Tretinoin': 2033, 'Vorinostat': 2034}\n"
     ]
    }
   ],
   "source": [
    "print(drug_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b8de0be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----0 to 64-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 8136)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEFINITIONS BEFORE FOR LOOP\n",
    "print('-----' + str(index) + ' to ' + str(upper_index) + '-----')\n",
    "tmp_batch_size = 0\n",
    "y_input_list = []\n",
    "drug_input_list = []\n",
    "x_batch = np.zeros((1, (num_feature * (num_gene + num_drug))))\n",
    "x_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b6903bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR LOOP over ROWS in batch range\n",
    "# ROW = Pandas(Index=0, _1='Vorinostat', _2='Docetaxel', _3='UO-31', Score=0.6666666666666666)\n",
    "# GENERATES x_batch, y_input_list, drug_input_list\n",
    "for row in split_input_df.iloc[index : upper_index].itertuples():\n",
    "    tmp_batch_size += 1\n",
    "    drug_a = row[1]\n",
    "    drug_b = row[2]\n",
    "    cellline_name = row[3]\n",
    "    if dataset == 'data-drugcomb-fi':\n",
    "        y = row[5]\n",
    "    else:\n",
    "        y = row[4]\n",
    "    one_drug_target_list = []\n",
    "    duo_drug_target_list = []\n",
    "    # GENERATES 2 lists:\n",
    "    # duo_drug_target_list : 0 everywhere (2016), except where both drugs influence GENE\n",
    "    # one_drug_target_list : 0 everywhere (2016), except only one of both drugs influences GENE\n",
    "    for gene in gene_name_list:\n",
    "        # CHECK if DRUG - GENE COMBINATION in list\n",
    "        # drugA_target and drugB_target or BOOLEANS\n",
    "        drugA_target = [drug_a, gene] in final_drugbank_comlist\n",
    "        drugB_target = [drug_b, gene] in final_drugbank_comlist\n",
    "        # CHECK IF both drugs INFLUENCE ONE GENE\n",
    "        if drugA_target and drugB_target:\n",
    "            one_drug_target_list.append(0.0)\n",
    "            duo_drug_target_list.append(1.0)\n",
    "        # IF NOT Check if one of them INFLUENCES the GENE\n",
    "        elif drugA_target or drugB_target:\n",
    "            one_drug_target_list.append(1.0)\n",
    "            duo_drug_target_list.append(0.0)\n",
    "        # IF NOT appends 0\n",
    "        else:\n",
    "            one_drug_target_list.append(0.0)\n",
    "            duo_drug_target_list.append(0.0)\n",
    "    # GENERATES features of for each GENE (2016) based on CELLLINE\n",
    "    # RNA (2016) and CNV (2016) \n",
    "    gene_rna_list = [float(x) for x in list(final_gdsc_rna_df[cellline_name])]\n",
    "    gene_cnv_list = [float(x) for x in list(final_gdsc_cnv_df[cellline_name])]\n",
    "    # COMBINE [drugA, drugB, rna, cmeth] \n",
    "    # creates long (2016 * 4) one dimensional list with 4 features per gene\n",
    "    x_input_list = []\n",
    "    for i in range(num_gene):\n",
    "    # APPEND DRUG INFORMATION\n",
    "        x_input_list.append(one_drug_target_list[i])\n",
    "        x_input_list.append(duo_drug_target_list[i])\n",
    "        # APPEND GENE FEATURES\n",
    "        x_input_list.append(gene_rna_list[i])\n",
    "        x_input_list.append(gene_cnv_list[i])\n",
    "    # IF NO drug features -> append zeros for each drug\n",
    "    if drug_feature == False:\n",
    "        fillin_list = [0.0] * num_feature\n",
    "        for i in range(num_drug):\n",
    "            x_input_list += fillin_list\n",
    "    # APPEND x_input vertically to prev x_inputs\n",
    "    # x_batch.shape (batchsize, 2016*4)\n",
    "    x_input = np.array(x_input_list)\n",
    "    x_batch = np.vstack((x_batch, x_input))\n",
    "    # APPEND drugs to list [A, B, A, B, A, B...]\n",
    "    drug_input_list.append(drug_dict[drug_a])\n",
    "    drug_input_list.append(drug_dict[drug_b])\n",
    "    # APPEND SCORE LIST\n",
    "    y_input_list.append(y)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6c67508a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 8136)\n",
      "(64, 1)\n",
      "(64, 2)\n"
     ]
    }
   ],
   "source": [
    "# DELETE first vertical COLUMS\n",
    "x_batch = np.delete(x_batch, 0, axis = 0)\n",
    "# CONVERT vector to 2D\n",
    "y_batch = np.array(y_input_list).reshape(tmp_batch_size, 1)\n",
    "# CONVERT DRUGS to 2D array\n",
    "drug_batch = np.array(drug_input_list).reshape(tmp_batch_size, 2)\n",
    "print(x_batch.shape)\n",
    "print(y_batch.shape)\n",
    "print(drug_batch.shape)\n",
    "# return x_batch, y_batch, drug_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8566d475",
   "metadata": {},
   "source": [
    "#### Return\n",
    "\n",
    "So we get `x_batch` which contains per ROW (DRG A, DRG B, CELLLINE, SCORE) <br>\n",
    "a 8136 1D array where for each GENE and DRUG, there are 4 entries: <br>\n",
    "`duo_target` (both drugs target a GENE) <br>\n",
    "`one_target` (one drug targets a GENE) <br>\n",
    "`rna feature` (rna feature depending on CELLLINE)<br> \n",
    "`cnv feature` (rna feature depending on CELLLINE)<br> \n",
    "\n",
    "We also get `y_batch` which contains per ROW (DRG A, DRG B, CELLLINE, SCORE) <br>\n",
    "one entry: <br>\n",
    "`score` (score) <br>\n",
    "\n",
    "We also get `drug_batch` which contains per ROW (DRG A, DRG B, CELLLINE, SCORE) <br>\n",
    "2 entries: <br>\n",
    "`Drug A` (Drug A) <br>\n",
    "`Drug B` (Drug B) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44f3fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
