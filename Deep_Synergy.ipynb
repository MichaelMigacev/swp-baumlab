{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vergleich von Baseline-Modellen mit DeepSynergy\n",
    "\n",
    "In diesem Notebook evaluiere ich klassische Regressionsmodelle (Random Forest, Ridge Regression) und vergleiche sie mit DeepSynergy. Alle Hyperparameter wurden aus dem Paper genommen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Importieren der Bibliotheken\n",
    "\n",
    "Hier importiere ich alle benötigten Bibliotheken:\n",
    "- `sklearn` für Modelltraining und Cross Validation\n",
    "- `pickle` und `numpy` für Datenverarbeitung\n",
    "- `matplotlib` für spätere Visualisierung\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest mit Nested Cross Validation\n",
    "\n",
    "Hier wird ein Random Forest Modell mithilfe von Cross Validation evaluiert.  \n",
    "Die äußere Schleife nutzt 5 Folds für die Modellbewertung, die innere GridSearchCV nutzt 3 Folds zur Auswahl der besten Hyperparameter pro Fold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (36996, 8846) (36996,)\n",
      "Test data: (9108, 8846) (9108,)\n"
     ]
    }
   ],
   "source": [
    "# Load normalized dataset from pickle file\n",
    "with open(\"data/data_test_fold0_tanh.p\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Training data for cross-validation (nested CV)\n",
    "X_train_all = data[2]\n",
    "y_train_all = data[6]\n",
    "\n",
    "# Test data used for DeepSynergy evaluation\n",
    "X_test = data[3]\n",
    "y_test = data[7]\n",
    "\n",
    "print(\"Training data:\", X_train_all.shape, y_train_all.shape)\n",
    "print(\"Test data:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten laden\n",
    "\n",
    "Die Daten wurden aus einer vorbereiteten Pickle-Datei geladen, die bereits die tanh-Normalisierung enthält (wie im Paper verwendet).  \n",
    "Für die Baseline-Vergleiche wurden `X_train_all` und `y_train_all` als vollständiger Trainingsdatensatz für die 5-fache Nested Cross Validation genutzt.  \n",
    "Die Daten `X_test` und `y_test` dienen später zur separaten Evaluation des DeepSynergy-Modells.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest mit Nested Cross Validation\n",
    "\n",
    "Hier wird ein Random Forest Regressor mit einer 5-fachen äußeren und einer 3-fachen inneren Cross Validation evaluiert.  \n",
    "Die Hyperparameter stammen aus dem Paper.  Getestet wurden 3 Varianten der Anzahl von Entscheidungsbäumen n_estimators.  \n",
    "Mit GridSearchCV wird innerhalb jedes Outer-Folds der beste Wert für n_estimators gesucht.  \n",
    "Die Bewertung erfolgt über den mittleren quadratischen Fehler (Mean Squared Error, MSE).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grid for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [128, 512, 1024],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "# Define inner and outer cross-validation\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "inner_cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "rf_mse_scores = []\n",
    "\n",
    "for train_idx, test_idx in outer_cv.split(X_train_all):\n",
    "    X_train, X_val = X_train_all[train_idx], X_train_all[test_idx]\n",
    "    y_train, y_val = y_train_all[train_idx], y_train_all[test_idx]\n",
    "\n",
    "    rf_model = RandomForestRegressor(random_state=0)\n",
    "    grid = GridSearchCV(\n",
    "        rf_model,\n",
    "        param_grid_rf,\n",
    "        cv=inner_cv,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_rf = grid.best_estimator_\n",
    "    predictions = best_rf.predict(X_val)\n",
    "    mse = mean_squared_error(y_val, predictions)\n",
    "    rf_mse_scores.append(mse)\n",
    "\n",
    "    print(f\"Fold MSE: {mse:.2f} | Best Params: {grid.best_params_}\")\n",
    "\n",
    "# Final summary\n",
    "print(\"\\nRandom Forest MSEs:\", rf_mse_scores)\n",
    "print(\"Mean Random Forest MSE:\", np.mean(rf_mse_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ergebnisse (aus Terminallauf):\n",
    "\n",
    "- Fold 1: 241.42\n",
    "- Fold 2: 295.49\n",
    "- Fold 3: 294.35\n",
    "- Fold 4: 290.07\n",
    "- Fold 5: 263.79\n",
    "\n",
    "** MSE: 277.02**\n",
    "\n",
    "Diese Ergebnisse zeigen, dass der Random Forest über alle Folds hinweg relativ stabile Vorhersageleistungen erzielt.  \n",
    "Die Schwankungen zwischen den Folds sind nicht hoch, was für ein robustes Modell spricht.  \n",
    "Mit einem durchschnittlichen MSE von 277.02 liefert Random Forest im Vergleich zu Ridge Regression und DeepSynergy eine sehr starke Baseline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression mit Nested Cross Validation\n",
    "\n",
    "Auch Ridge Regression wird mit einer 5-fachen verschachtelten Cross Validation (Nested CV) evaluiert.   \n",
    "Die getesteten Werte 0.1, 1.0, 10.0, 100.0 stammen ebenfalls aus dem DeepSynergy-Paper.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grid for Ridge Regression\n",
    "param_grid_ridge = {\n",
    "    'alpha': [0.1, 1.0, 10.0, 100.0]\n",
    "}\n",
    "\n",
    "ridge_mse_scores = []\n",
    "\n",
    "# Loop through outer folds\n",
    "for train_idx, test_idx in outer_cv.split(X_train_all):\n",
    "    X_train, X_val = X_train_all[train_idx], X_train_all[test_idx]\n",
    "    y_train, y_val = y_train_all[train_idx], y_train_all[test_idx]\n",
    "\n",
    "    ridge = Ridge()\n",
    "    grid_ridge = GridSearchCV(\n",
    "        ridge,\n",
    "        param_grid_ridge,\n",
    "        cv=inner_cv,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1  # use all CPU cores\n",
    "    )\n",
    "    grid_ridge.fit(X_train, y_train)\n",
    "    best_ridge = grid_ridge.best_estimator_\n",
    "    predictions = best_ridge.predict(X_val)\n",
    "    mse = mean_squared_error(y_val, predictions)\n",
    "    ridge_mse_scores.append(mse)\n",
    "\n",
    "    print(f\"Fold MSE: {mse:.2f} | Best alpha: {grid_ridge.best_params_['alpha']}\")\n",
    "\n",
    "# Final summary\n",
    "print(\"\\nRidge Regression MSEs:\", ridge_mse_scores)\n",
    "print(\"Mean Ridge Regression MSE:\", np.mean(ridge_mse_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ergebnisse (aus Terminallauf):\n",
    "\n",
    "- Fold 1: 385.14\n",
    "- Fold 2: 453.62\n",
    "- Fold 3: 444.98\n",
    "- Fold 4: 440.76\n",
    "- Fold 5: 405.29\n",
    "\n",
    "**MSE: 425.96**\n",
    "\n",
    "Diese Ergebnisse zeigen deutlich, dass Ridge Regression im Vergleich zu Random Forest deutlich schlechter abschneidet.  \n",
    "Die Fehlerstreuung ist relativ hoch und die Performance bleibt in allen Folds klar hinter dem Random Forest zurück.  \n",
    "Das bestätigt, dass lineare Modelle für dieses Problem weniger geeignet sind.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepSynergy (PyTorch-Reimplementierung)\n",
    "\n",
    "\n",
    "Die Evaluation erfolgt nur auf dem festen Testset (`X_test`, `y_test`), da keine Cross Validation verwendet wurde.  \n",
    "Daher ist der Vergleich zu den Baselines nur eingeschränkt direkt vergleichbar. Ich habe das Modell nichtmehr mit Cross Validation trainieren können, ich hoffe das hat Michael gemacht als er DeepSynergy nachgebaut hat? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DeepSynergy model architecture\n",
    "class DeepSynergyModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(DeepSynergyModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(input_size, 8192),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(8192, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Load trained model and evaluate on test set\n",
    "model = DeepSynergyModel(input_size=X_test.shape[1])\n",
    "model.load_state_dict(torch.load(\"deepsynergy_model.pt\", map_location=\"cpu\"))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    X_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_pred = model(X_tensor).squeeze().numpy()\n",
    "\n",
    "mse_deepsynergy = mean_squared_error(y_test, y_pred)\n",
    "print(f\"DeepSynergy MSE on test set: {mse_deepsynergy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ergebnis (aus Terminallauf):\n",
    "\n",
    "**DeepSynergy MSE (Testset Fold 0): 332.73**\n",
    "\n",
    "Im Vergleich zu Random Forest (MSE: 277.02) liegt DeepSynergy deutlich höher.  \n",
    "Trotzdem performt es besser als Ridge Regression (MSE: 425.96).  \n",
    "Ein direkter Vergleich ist jedoch methodisch nicht ganz fair, da wie schon erwähnt, DeepSynergy nicht per Cross Validation evaluiert wurde."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zusammenfassung der Ergebnisse\n",
    "\n",
    "| Modell           | Evaluationsmethode            | MSE     |\n",
    "|------------------|-------------------------------|---------|\n",
    "| Random Forest    | 5-fold Nested Cross Validation | 277.02  |\n",
    "| Ridge Regression | 5-fold Nested Cross Validation | 425.96  |\n",
    "| DeepSynergy      | Testsplit (Fold 0)             | 332.73  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazit\n",
    "\n",
    "Obwohl DeepSynergy als tiefes neuronales Netz grundsätzlich in der Lage ist, komplexe Zusammenhänge zu modellieren, war die Umsetzung in diesem Projekt durch reduzierte Trainingszeit und vereinfachte Architektur limitiert.  \n",
    "Ein vollständig trainiertes DeepSynergy mit optimierten Hyperparametern könnte bessere Ergebnisse liefern.\n",
    "\n",
    "Die Ergebnisse bestätigen, dass klassische Modelle wie Random Forest auch in modernen Aufgabenstellungen konkurrenzfähig bleiben.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
